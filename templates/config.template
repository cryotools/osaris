#####################################################
#
# OSARIS configuration template
#
####################################################


# - - - - - GENERAL - - - - - - - - - - - - - - - - - 

debug=1
# Debug level
# 0 - none, 1 - moderate, 2 - maximum output

prefix="my_prefix"
# Used to group all data of the run.
# Typically use the name of the study region, e.g. "central-alps"

SAR_sensor="Sentinel"
SAR_datatype="TOPS"
swaths_to_process=(1 2 3)

polarization="vv"
# Define which polarization should be used (optional, default "vv")
# Options (for Sentinel-1 IW):
# vv
# vh


# Area of interest
# Coordinates and elevation of upper-left and lower-right corner 
# points of area of interest in decimal degrees (-180 to 180 notation for longitude values).

lon_1=12.34
lat_1=34.56

lon_2=56.78
lat_2=78.90


# Activate cutting of result grids to the extent of area of interest
# (0 = no, 1 = yes).
cut_to_aoi=1


# - - - - - BASE DATA PATHES - - - - - - - - - - - - - - -

base_PATH="/my/path/OSARIS-results/"
# Path to directory where OSARIS will put all files

topo_PATH="/my/path/DEM/"
# Path to directory containing topo data (dem.grd file)
# Generate at http://topex.ucsd.edu/gmtsar/demgen/

input_files="download"
# Options:
# download - use the DHuS script to obtain data, configure, below
# full path to a directory containing the S1 scene to process, e.g. /data/S1-scenes 

orig_files="extract"
# Options:
# extract - Unizp files from input folder
# keep - recommended when files were already extracted in a previous run

orbits_PATH="/path/to/orbits_folder"
# Path to S1 orbit data
# Existing orbits will be used
# If folder does not exist or is empty, orbits will be downloaded here
# --> make sure to set $update_orbits to "1"

update_orbits=0
# Activate (1) or deactivate (0) automatic orbit retrieval

credentials_file="$OSARIS_PATH/config/login.credentials"
# File containing login credentials for file downloads
# To create a new file please use the login.credentials file in the templates directory.


# - - - - - GMTSAR CONFIG FILE - - - - - - - - - - - - - 

# File name of GMTSAR config file. Specify full path if the file is
# not located in the program directory (along with this config file)
gmtsar_config_file="config/GMTSAR.config"


# - - - - - PROCESSING CONFIGURATION - - - - - - - - - - - - - - - - 

process_intf_mode=pairs
# Mode to process interferograms.
# pairs -> Chronologicallay moving pairs (A-B, B-C, C-D, ...)
# single_master -> Fixed master (A-B, A-C, A-D, ...)

# master_scene_date=20160217
# Optionally specify the scene to use as Master in single_master mode

process_reverse_intfs=0
# Activate processing of inverse interferograms (0 = no,1 = yes)
# Master and slave image will be switched and differences between
# original and reverse interferograms will be calculated.
# Primarily useful to assess phase unwrapping errors.
# Warning: Will need a lot of extra computing time. 


# Use the following parameters to skip processing steps.
# Useful to run additional modules on data created by a previous run.
skip_pre_processing=0
# Will skip preprocessing processing (extracting raw files, cut+merge, etc.).
skip_intf_processing=0
# Will skip the complete GMTSAR interferometric processing.


# - - - - - MODULES - - - - - - - - - - - - - - - - - - -

# Note that some modules may require a separate configuration file.
# For these, make sure that for each acitvated module a configuration file 
# 'module_name.config' is located in the config folder. Copy the 
# template file from the module folder and fit it to your needs.

module_config_PATH=""
# Optionally, provide a path to where module configuration for this run is stored.
# If not set and modules are activated (see section MODULES below), OSARIS will
# look for module configuration in the directory config/ within the OSARIS installation
# directory.
# Relative pathes will be interpreted as subdirectories of the config directory.
# Alternatively, you may the global variable $OSARIS_PATH to indicate directories
# below the OSARIS installation directory, e.g. "$OSARIS_PATH/config/central-alps

post_download_mods=( )
# Modules to be run after downloading the S1 datasets
# Recommended for:
#   - ping

post_extract_mods=( )
# Modules to be run after extracting the data S1 scenes

post_processing_mods=( summary_pdf )
# Modules to be run after GMTSAR processing
# Recommended for:
#   - sgp_identification
#   - harmonize_grids
#   - unstable_coh_metric 
#   - timeseries_xy 
#   - statistics 
#   - grid_difference 
#   - summary_pdf

post_postprocessing_mods=( )
# Modules to be run after calculating statistics and preparing summary reports


# - - - - - SLURM CONFIGURATION - - - - - - - - - - - - - -

slurm_account=your_account
# SLURM account name

slurm_partition=your_partition
# Partition used for computing.
# Optional in most cases, comment out when not needed

slurm_ntasks=5
# Number of cores used for parallel processing. 
# Fit this number to make sure sufficient RAM (~15 GB for full S1 swath) is available for processing.
# For example, when 3 GB of RAM are allocated for each core, use 5 or more ntasks.

# slurm_partition_alt=your_alt_partition
# Alternative partition (optional)
# If activated, jobs will be send to this partition when no free cores are available in slurm_partition.

# slurm_ntasks_alt=10
# Number of cores to be used per job on the alternative partition 
# (only used in combination with slurm_partition_alt).

slurm_jobname_prefix="Prefix"
# Choose a name to identify your jobs in the SLURM queue

# slurm_extract_qos=your_extract_qos
# Job type for extract jobs
# Optional, only required if different from other processing, 
# e.g. because of unzip is not installed on processing nodes

# slurm_extract_partition=your_extract_partition
# Partition used for computing.
# Optional, only required by Slurm config and when different from partition defined with 'slurm_partition'

slurm_mailtype=ALL
# SLURM mail setup. 
# Optional in most cases, comment out when not needed


# - - - - - DOWNLOADS AND DATA - - - - - - - - - - - - 


scene_provider=ESA
# Provider from which to download Sentinel-1 scenes
# ESA -> Use ESA DHuS API
# ASF -> Use the EarthData platform by the University of Alaska in Fairbanks

orbit_provider=ASF
# Provider from which to download Sentinel-1 scenes
# ESA -> Use ESA DHuS API
# ASF -> Use the EarthData platform by the University of Alaska in Fairbanks


### S1 scene download configuration
### Only required when $input_files is set to 'download'

# relative_orbit=
# Set a relative orbit to constrain your processing to ascending or descending data takes.
# The right orbit number can be identified via 'View product details' (eye icon) in search 
# results at https://scihub.copernicus.eu/dhus/

# Timing configuration
# Date format is ISO 8601, YYYY-MM-DDThh:mm:ss.cccZ (e.g. -s 2016-10-02T06:00:00.000Z)
sensing_period_start="2015-01-01T00:00:00.000Z"
sensing_period_end="NOW"
ingestion_period_start="2015-01-01T00:00:00.000Z"
ingestion_period_end="NOW"



# - - - - - CLEAN UP - - - - - - - - - - - - - - - - 

clean_up=0
# Delete files used for processing after finishing the job
# 0 or not set -> Keep all files
# 1 -> Delete files solely used for this run (will keep extracted S1 files for subsequent jobs)
# 2 -> Delete the whole processing folder


